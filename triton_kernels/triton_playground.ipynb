{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import triton\n",
    "import triton.language as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE = 'cuda:0'\n",
    "# torch_device = torch.device(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.version.cuda)  # Should match your system CUDA version\n",
    "!nvcc --version  # Check system-wide CUDA version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel to load every other element from a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def stride_copy_kernel(in_ptr, out_ptr, N, BLOCK_SIZE: tl.constexpr):\n",
    "    pid = tl.program_id(0)\n",
    "    offsets = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n",
    "\n",
    "    # Mask for input (every other element)\n",
    "    input_mask = (offsets * 2) < N\n",
    "    \n",
    "    # Mask for output (contiguous elements)\n",
    "    output_mask = offsets < (N // 2)\n",
    "\n",
    "    inp_data = tl.load(in_ptr + (2 * offsets), mask=input_mask)\n",
    "    alt_inp_data = tl.load(in_ptr + (2 * offsets + 1), mask=input_mask)\n",
    "    tl.store(out_ptr + offsets, alt_inp_data, mask=output_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper function to launch the kernel\n",
    "def stride_copy_wrapper(input_tensor, output_tensor):\n",
    "    # Assume last dimension is the one to stride over\n",
    "    n_elements = input_tensor.shape[-1]\n",
    "    assert n_elements % 2 == 0, \"Input tensor must have an even number of elements\"\n",
    "    \n",
    "    BLOCK_SIZE = 64\n",
    "    grid = (triton.cdiv(n_elements // 2, BLOCK_SIZE),)\n",
    "    \n",
    "    stride_copy_kernel[grid](\n",
    "        input_tensor, \n",
    "        output_tensor, \n",
    "        n_elements, \n",
    "        BLOCK_SIZE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input tensor\n",
    "input_tensor = torch.arange(300, dtype=torch.float32, device='cuda')\n",
    "# Create output tensor to hold the result\n",
    "output_tensor = torch.empty(150, dtype=torch.float32, device='cuda')\n",
    "\n",
    "# Call the wrapper function\n",
    "stride_copy_wrapper(input_tensor, output_tensor)\n",
    "\n",
    "# Verify the result\n",
    "print(output_tensor)  # Should contain [1, 3, 5, ..., 31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RoPE Forward Pass Implementation\n",
    "\n",
    "A work in progress implementation of RoPE forward pass in Triton.\n",
    "Trying to understand the micro kernels required to make this efficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "# The d-head dimension\n",
    "n_elements = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the initial implementation for the RoPE kernel in Triton\n",
    "import triton\n",
    "import triton.language as tl\n",
    "import torch\n",
    "\n",
    "@triton.jit\n",
    "def rope_kernel(\n",
    "    q_ptr,\n",
    "    k_ptr,\n",
    "    cos_ptr,\n",
    "    sin_ptr,\n",
    "    out_ptr,\n",
    "    n_elements,\n",
    "    BLOCK_SIZE: tl.constexpr  # Block size for parallel processing\n",
    "):\n",
    "    # Define the program's index in the grid\n",
    "    pid = tl.program_id(0)\n",
    "\n",
    "    offsets = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n",
    "    # Mask for input (every other element)\n",
    "    input_mask = (offsets * 2) < n_elements\n",
    "    # Mask for loading the sinusoid values, up to dmodel // 2\n",
    "    sinusoid_mask = offsets < (n_elements // 2)\n",
    "    \n",
    "    q_real = tl.load(q_ptr + (2 * offsets), mask=input_mask)\n",
    "    q_imag = tl.load(q_ptr + (2 * offsets + 1), mask=input_mask)\n",
    "    k_real = tl.load(k_ptr + (2 * offsets), mask=input_mask)\n",
    "    k_imag = tl.load(k_ptr + (2 * offsets + 1), mask=input_mask)\n",
    "\n",
    "    cos = tl.load(cos_ptr + offsets, mask=sinusoid_mask)\n",
    "    sin = tl.load(sin_ptr + offsets, mask=sinusoid_mask)\n",
    "\n",
    "    q_rotated_real = q_real * cos - q_imag * sin\n",
    "    q_rotated_imag = q_real * sin + q_imag * cos\n",
    "    k_rotated_real = k_real * cos - k_imag * sin\n",
    "    k_rotated_imag = k_real * sin + k_imag * cos\n",
    "\n",
    "    # Store rotated vectors back to memory\n",
    "    output_mask = offsets < n_elements\n",
    "    tl.store(out_ptr + offsets * 2, q_rotated_real, mask=output_mask)\n",
    "    tl.store(out_ptr + offsets * 2 + 1, q_rotated_imag, mask=output_mask)\n",
    "    # tl.store(out_ptr + n_elements * 2 + offsets * 2, k_rotated_real, mask=output_mask)\n",
    "    # tl.store(out_ptr + n_elements * 2 + offsets * 2 + 1, k_rotated_imag, mask=output_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class RoPEEmbeddings(nn.Module):\n",
    "    def __init__(self, dim, max_seq_len=4096, base=10000):\n",
    "        super(RoPEEmbeddings, self).__init__()\n",
    "        assert dim % 2 == 0, \"dim must be even for RoPE.\"\n",
    "        self.dim = dim\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.base = base\n",
    "\n",
    "        self.register_buffer(\"inv_freq\",\n",
    "            1.0 / (self.base ** (torch.arange(0, dim, 2).float() / dim)), persistent=False)\n",
    "\n",
    "        self.build_rope_cache()\n",
    "\n",
    "    # Add the function to rotate half\n",
    "    def rotate_half(self, x): \n",
    "        x1, x2 = x.chunk(2, dim=-1)\n",
    "        return torch.cat((-x2, x1), dim=-1)\n",
    "    \n",
    "    def build_rope_cache(self):\n",
    "        # Use this to precompute the RoPE cache\n",
    "        pos_array = torch.arange(self.max_seq_len)\n",
    "        theta = pos_array.unsqueeze(-1) * self.inv_freq\n",
    "        cos = torch.cos(theta)\n",
    "        sin = torch.sin(theta)\n",
    "        #\n",
    "        # Disable any interleaving or duplicating. CUDA doesn't need it.\n",
    "        # cos = torch.cat([cos, cos], dim=-1)\n",
    "        # sin = torch.cat([sin, sin], dim=-1)\n",
    "        # instead do y[2i], y[2i+1] = x[i], x[i]\n",
    "        # cos = torch.repeat_interleave(cos, repeats=2, dim=-1)\n",
    "        # sin = torch.repeat_interleave(sin, repeats=2, dim=-1)\n",
    "\n",
    "        self.register_buffer(\"cos\", cos, persistent=False)\n",
    "        self.register_buffer(\"sin\", sin, persistent=False)\n",
    "\n",
    "    def forward(self, x, positions=None):\n",
    "        # Postitions is unused for now.\n",
    "        out_real = x[..., ::2] * self.cos - x[..., 1::2] * self.sin\n",
    "        out_imag = x[..., ::2] * self.sin + x[..., 1::2] * self.cos\n",
    "        # Is there a better way to do this?\n",
    "        out_interleaved = torch.cat((out_real.unsqueeze(-1),\n",
    "                                    out_imag.unsqueeze(-1)), dim=-1)\n",
    "        return out_interleaved.flatten(-2)\n",
    "\n",
    "\n",
    "rope_ref = RoPEEmbeddings(n_elements, max_seq_len=1).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda:0' # There should be a better way to capture this\n",
    "q_ptr = torch.randn((1, n_elements), device=DEVICE)\n",
    "k_ptr = torch.randn((1, n_elements), device=DEVICE)\n",
    "out_ptr = torch.zeros((1, n_elements), device=DEVICE)\n",
    "\n",
    "torch_device = torch.device(DEVICE)\n",
    "assert q_ptr.device == torch_device and k_ptr.device == torch_device and \\\n",
    "    out_ptr.device == torch_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a 1D grid.\n",
    "grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']), )\n",
    "rope_kernel[grid](\n",
    "    q_ptr,\n",
    "    k_ptr,\n",
    "    rope_ref.cos,\n",
    "    rope_ref.sin,\n",
    "    out_ptr,\n",
    "    n_elements,\n",
    "    BLOCK_SIZE=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtune.modules import RotaryPositionalEmbeddings\n",
    "\n",
    "# Initialize the RoPE module\n",
    "rope = RotaryPositionalEmbeddings(dim=n_elements, max_seq_len=1).to(q_ptr.device)\n",
    "\n",
    "# Apply RoPE to the input tensor\n",
    "x_transformed = rope(q_ptr.view(1, 1, 1, n_elements))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing `torchtune` RopeEmbeddings with our implementation\n",
    "# and Triton implementation.\n",
    "print(torch.allclose(x_transformed, rope_ref(q_ptr)))\n",
    "print(torch.allclose(x_transformed, out_ptr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flash Attention\n",
    "\n",
    "Following the tutorial from https://www.youtube.com/watch?v=zy8ChVd_oTM&t=7049s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention forward inner\n",
    "@triton.jit\n",
    "def _attn_fwd_inner(\n",
    "    O_block,\n",
    "    m_i,\n",
    "    l_i,\n",
    "    Q_block,\n",
    "    K_block_ptr,\n",
    "    V_block_ptr,\n",
    "    block_index_q,\n",
    "    softmax_scale,\n",
    "    BLOCK_SIZE_Q: tl.constexpr,\n",
    "    BLOCK_SIZE_KV: tl.constexpr,\n",
    "    STAGE: tl.constexpr,\n",
    "    offs_q: tl.constexpr,\n",
    "    offs_kv: tl.constexpr,\n",
    "    SEQ_LEN: tl.constexpr,\n",
    "):\n",
    "    # range of values handled by the current stage.\n",
    "    # Need to understand why STAGE values here are different from the\n",
    "    # STAGE values passed in the _attn_fwd kernel, i.e. why STAGE = 4 - STAGE?\n",
    "    if STAGE == 1:\n",
    "        # All the blocks to the left of the diagonal in the causal/non-causal attention.\n",
    "        lo, hi = 0, block_index_q * BLOCK_SIZE_Q\n",
    "    elif STAGE == 2:\n",
    "        # Blocks on the diagonal in causal attention.\n",
    "        lo, hi = block_index_q * BLOCK_SIZE_Q, (block_index_q + 1) * BLOCK_SIZE_Q\n",
    "        lo = tl.multiple_of(lo, BLOCK_SIZE_Q)\n",
    "    else:\n",
    "        # only used in non-causal attention.\n",
    "        ...\n",
    "\n",
    "    # This is the block of K and V that we are processing.\n",
    "    # advance the pointer to the start of the block depending on the call\n",
    "    # to this function.\n",
    "    K_block_ptr = tl.advance(K_block_ptr, (0, lo))\n",
    "    V_block_ptr = tl.advance(V_block_ptr, (lo, 0))\n",
    "\n",
    "    for start_kv in range(lo, hi, BLOCK_SIZE_KV):\n",
    "        # Let the compiler know that start_kv is a multiple of BLOCK_SIZE_KV.\n",
    "        start_kv = tl.multiple_of(start_kv, BLOCK_SIZE_KV)\n",
    "\n",
    "        K_block = tl.load(K_block_ptr, mask=None)\n",
    "        # Remember K_block is already transposed.\n",
    "        QK_block = tl.dot(Q_block, K_block)\n",
    "\n",
    "        # if STAGE == 2, we know some values will be valid and some will be non-causal\n",
    "        if STAGE == 2:\n",
    "            mask = offs_q[:, None] >= (start_kv + offs_kv[None, :])\n",
    "            QK_block = QK_block * softmax_scale + tl.where(mask, 0.0, -1.0e6)\n",
    "            m_ij = tl.maximum(m_i, tl.max(QK_block, axis=1))\n",
    "            QK_block -= m_ij[:, None]\n",
    "        else:\n",
    "            m_ij = tl.maximum(m_i, tl.max(QK_block, axis=1) * softmax_scale)\n",
    "            QK_block = QK_block * softmax_scale - m_ij[:, None]\n",
    "        \n",
    "        # Compute the exponent of each dot product\n",
    "        P_block = tl.math.exp(QK_block)\n",
    "\n",
    "        # For the current block, compute the sum of the probabilities.\n",
    "        l_ij = tl.sum(P_block, axis=1)\n",
    "\n",
    "        # Correction factor; m_i = running max of the softmax block.\n",
    "        alpha = tl.math.exp(m_i - m_ij)\n",
    "\n",
    "        l_i = l_i * alpha + l_ij\n",
    "\n",
    "        V_block = tl.load(V_block_ptr, mask=None)\n",
    "\n",
    "        O_block = O_block * alpha[:, None]\n",
    "        # C = tl.dot(A, B, C) --> C += A @ B\n",
    "        # Does this invoke the MAC?\n",
    "        P_block = P_block.to(tl.float16)\n",
    "        O_block = tl.dot(P_block, V_block, O_block)\n",
    "\n",
    "        m_i = m_ij\n",
    "\n",
    "        K_block_ptr = tl.advance(K_block_ptr, (0, BLOCK_SIZE_KV))\n",
    "        V_block_ptr = tl.advance(V_block_ptr, (BLOCK_SIZE_KV, 0))\n",
    "\n",
    "    return O_block, l_i, m_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.autotune(\n",
    "    [\n",
    "        triton.Config(\n",
    "            {\"BLOCK_SIZE_Q\": BLOCK_SIZE_Q, \"BLOCK_SIZE_KV\": BLOCK_SIZE_KV},\n",
    "            num_stages=num_stages,\n",
    "            num_warps=num_warps,\n",
    "        )\n",
    "        for BLOCK_SIZE_Q in [64] # , 128]\n",
    "        for BLOCK_SIZE_KV in [32] #, 64]\n",
    "        for num_stages in ([3])\n",
    "        for num_warps in [2]\n",
    "    ],\n",
    "    key=[\"SEQ_LEN\", \"HEAD_DIM\"],\n",
    ")\n",
    "\n",
    "@triton.jit\n",
    "def _attn_fwd(\n",
    "    Q,  # BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM\n",
    "    K,  # BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM\n",
    "    V,  # BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM\n",
    "    O,  # BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM\n",
    "    M,  # BATCH_SIZE, NUM_HEADS, SEQ_LEN\n",
    "    softmax_scale,\n",
    "    stride_Q_batch,\n",
    "    stride_Q_head,\n",
    "    stride_Q_seq,\n",
    "    stride_Q_dim,\n",
    "    stride_K_batch,\n",
    "    stride_K_head,\n",
    "    stride_K_seq,\n",
    "    stride_K_dim,\n",
    "    stride_V_batch,\n",
    "    stride_V_head,\n",
    "    stride_V_seq,\n",
    "    stride_V_dim,\n",
    "    stride_O_batch,\n",
    "    stride_O_head,\n",
    "    stride_O_seq,\n",
    "    stride_O_dim,\n",
    "    BATCH_SIZE,\n",
    "    NUM_HEADS: tl.constexpr,\n",
    "    SEQ_LEN: tl.constexpr,\n",
    "    HEAD_DIM: tl.constexpr,\n",
    "    BLOCK_SIZE_Q: tl.constexpr,\n",
    "    BLOCK_SIZE_KV: tl.constexpr,\n",
    "    STAGE: tl.constexpr,\n",
    "):\n",
    "    tl.static_assert(BLOCK_SIZE_KV <= HEAD_DIM)\n",
    "    \n",
    "    block_index_q = tl.program_id(0)\n",
    "    index_batch_head = tl.program_id(1)\n",
    "    index_batch = index_batch_head // NUM_HEADS\n",
    "    index_head = index_batch_head % NUM_HEADS\n",
    "\n",
    "    # Index into Q to figure out where does the head start\n",
    "    qkv_offset = (\n",
    "        index_batch.to(tl.int64) * stride_Q_batch\n",
    "        + index_head.to(tl.int64) * stride_Q_head\n",
    "    )\n",
    "\n",
    "    # stride_Q_batch, stride_Q_head, stride_Q_seq, stride_Q_dim - These are obtained directly from the tensor.\n",
    "    # stride_Q_batch = how much to add to get to the next batch.\n",
    "    # stride_Q_head = how much to add to get to the next head in the same batch.\n",
    "    # stride_Q_seq = how much to add to get to the next sequence in the same head and batch.\n",
    "    # stride_Q_dim = how much to add to get to the next dimension in the same sequence, head and batch.\n",
    "    q_block_ptr = tl.make_block_ptr(  # Q[index_batch, index_head, block_index_q * BLOCK_SIZE_Q, :]\n",
    "        base=Q + qkv_offset,  # a 2D tensor\n",
    "        shape=(SEQ_LEN, HEAD_DIM),\n",
    "        # stride_Q_seq: Specifies how many elements you need to move in memory to go from one row to the next\n",
    "        # stride_Q_dim: Specifies how many elements you need to move in memory to go from one column to the next in the same row.\n",
    "        strides=(stride_Q_seq, stride_Q_dim),\n",
    "        block_shape=(BLOCK_SIZE_Q, HEAD_DIM),\n",
    "        # In the tensor view, the start offsets of the queries this block will work on.\n",
    "        offsets=(block_index_q * BLOCK_SIZE_Q, 0),\n",
    "        # Order means the indexing should prioritize the second axis first, followed by the first axis.\n",
    "        # i.e. data in the block is processed column-wise before row-wise.\n",
    "        order=(1, 0)\n",
    "    )\n",
    "    \n",
    "    # NOTE: Not skipping KVs into a block of KVs.\n",
    "    v_block_ptr = tl.make_block_ptr(\n",
    "        base=V + qkv_offset,\n",
    "        shape=(SEQ_LEN, HEAD_DIM),\n",
    "        strides=(stride_V_seq, stride_V_dim),\n",
    "        block_shape=(BLOCK_SIZE_KV, HEAD_DIM),\n",
    "        offsets=(0, 0),\n",
    "        # TODO: what is this order?\n",
    "        order=(1, 0)\n",
    "    )\n",
    "\n",
    "    # K should be indexed in the transposed manner.\n",
    "    k_block_ptr = tl.make_block_ptr(\n",
    "        base=K + qkv_offset,\n",
    "        shape=(HEAD_DIM, SEQ_LEN),\n",
    "        strides=(stride_K_dim, stride_K_seq),\n",
    "        block_shape=(HEAD_DIM, BLOCK_SIZE_KV),\n",
    "        # offsets are (0, 0) because we are not skipping anything. We are at the beginning of the cache block\n",
    "        offsets=(0, 0),\n",
    "        # If ordering is to prioritize the first axis first followed by the second axis and we are already\n",
    "        # transposing the K block, then is this order negating the transpose?\n",
    "        # TODO - really understand what this order means.\n",
    "        order=(0, 1)\n",
    "    )\n",
    "\n",
    "    # How many outputs do we generate?\n",
    "    O_block_ptr = tl.make_block_ptr(  # O[index_batch, index_head, block_index_q * BLOCK_SIZE_Q, :]\n",
    "        base=O + qkv_offset,\n",
    "        shape=(SEQ_LEN, HEAD_DIM),\n",
    "        strides=(stride_O_seq, stride_O_dim),\n",
    "        block_shape=(BLOCK_SIZE_Q, HEAD_DIM),\n",
    "        offsets=(block_index_q * BLOCK_SIZE_Q, 0),\n",
    "        order=(1, 0)\n",
    "    )\n",
    "\n",
    "    # load Q blocks\n",
    "    Q_block = tl.load(q_block_ptr, mask=None)\n",
    "\n",
    "    offs_q = block_index_q * BLOCK_SIZE_Q + tl.arange(0, BLOCK_SIZE_Q)\n",
    "\n",
    "    # offs_kv: the offsets for the token in the K and V sequence to process\n",
    "    offs_kv = tl.arange(0, BLOCK_SIZE_KV)\n",
    "\n",
    "    # m_i: the running maximum of the softmax block.\n",
    "    m_i = tl.zeros([BLOCK_SIZE_Q], dtype=tl.float32) - float('inf')\n",
    "\n",
    "    # l_i: the running sum of the softmax block. We have one for each query\n",
    "    l_i = tl.zeros([BLOCK_SIZE_Q], dtype=tl.float32) + 1.0  # added in the algorithm\n",
    "\n",
    "    # output block for the current rows of query.\n",
    "    o_block = tl.zeros([BLOCK_SIZE_Q, HEAD_DIM], dtype=tl.float32)\n",
    "\n",
    "    # What are stages? Just following the tutorial for now.\n",
    "    if STAGE == 1 or STAGE == 3:\n",
    "        # This step runs for the blocks to the left of the diagonal in causal attention\n",
    "        o_block, l_i, m_i = _attn_fwd_inner(\n",
    "            o_block,\n",
    "            m_i,\n",
    "            l_i,\n",
    "            Q_block,\n",
    "            k_block_ptr,\n",
    "            v_block_ptr,\n",
    "            block_index_q,\n",
    "            softmax_scale,\n",
    "            BLOCK_SIZE_Q,\n",
    "            BLOCK_SIZE_KV,\n",
    "            4 - STAGE,\n",
    "            offs_q,\n",
    "            offs_kv,\n",
    "            SEQ_LEN\n",
    "        )\n",
    "\n",
    "    if STAGE == 3:\n",
    "        # This step runs for the blocks to the right of the diagonal in the causal attention\n",
    "        o_block, l_i, m_i = _attn_fwd_inner(\n",
    "            o_block,\n",
    "            m_i,\n",
    "            l_i,\n",
    "            Q_block,\n",
    "            k_block_ptr,\n",
    "            v_block_ptr,\n",
    "            block_index_q,\n",
    "            softmax_scale,\n",
    "            BLOCK_SIZE_Q,\n",
    "            BLOCK_SIZE_KV,\n",
    "            2,  # I have no idea why these weird Stage numberings.\n",
    "            offs_q,\n",
    "            offs_kv,\n",
    "            SEQ_LEN\n",
    "        )\n",
    "\n",
    "    # Indeed a smart trick. No longer need to divide and rather just do a lot of subtract.\n",
    "    m_i += tl.math.log(\n",
    "        l_i\n",
    "    ) # This is needed to compute the logsumexp for the backward pass. But I don't care right now.\n",
    "\n",
    "    o_block = o_block / l_i[:, None]\n",
    "\n",
    "    # M --> BATCH_SIZE, NUM_HEADS, SEQ_LEN\n",
    "    # index_batch_head --> heads in a batch are laid out contiguously and each\n",
    "    # head has a SEQ_LEN long logsumexp.\n",
    "    # M = points to the beginning of the tensor\n",
    "    # offs_q = points to the beginning of the block of queries we are processing in this block\n",
    "    m_ptrs = M + index_batch_head * SEQ_LEN + offs_q\n",
    "\n",
    "    tl.store(m_ptrs, m_i, mask=None)\n",
    "    tl.store(O_block_ptr, o_block.to(O.type.element_ty), mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to define a function that we can backpropagate through, the class needs to be\n",
    "# derived from torch.autograd.Function.\n",
    "\n",
    "class TritonAttention(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, Q, K, V, causal, softmax_scale):\n",
    "        # ctx allows us to save intermediate results for backward pass.\n",
    "\n",
    "        HEAD_DIM_Q, HEAD_DIM_K, HEAD_DIM_V = Q.shape[-1], K.shape[-1], V.shape[-1]\n",
    "        assert HEAD_DIM_Q == HEAD_DIM_K and HEAD_DIM_K == HEAD_DIM_V\n",
    "\n",
    "        BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM = Q.shape\n",
    "\n",
    "        O = torch.empty_like(Q)\n",
    "\n",
    "        # What is stage?\n",
    "        stage = 3 if causal else 1\n",
    "        \n",
    "        # Parallelize over the batch dimension and the number of heads\n",
    "        grid = lambda args: (\n",
    "            # ceil(SEQ_LEN / BLOCK_SIZE_Q) = How many blocks of Q we have.\n",
    "            triton.cdiv(SEQ_LEN, args['BLOCK_SIZE_Q']),\n",
    "            BATCH_SIZE * NUM_HEADS,\n",
    "            1, # z in the CUDA launch grid\n",
    "        )\n",
    "\n",
    "        # M is the logsumexp for the backward pass, one for each query.\n",
    "        M = torch.empty((BATCH_SIZE, NUM_HEADS, SEQ_LEN), device=Q.device, dtype=torch.float32)\n",
    "\n",
    "        _attn_fwd[grid](\n",
    "            Q=Q,\n",
    "            K=K,\n",
    "            V=V,\n",
    "            O=O,\n",
    "            M=M,\n",
    "            softmax_scale=softmax_scale,\n",
    "            stride_Q_batch=Q.stride(0),\n",
    "            stride_Q_head=Q.stride(1),\n",
    "            stride_Q_seq=Q.stride(2),\n",
    "            stride_Q_dim=Q.stride(3),\n",
    "            stride_K_batch=K.stride(0),\n",
    "            stride_K_head=K.stride(1),\n",
    "            stride_K_seq=K.stride(2),\n",
    "            stride_K_dim=K.stride(3),\n",
    "            stride_V_batch=V.stride(0),\n",
    "            stride_V_head=V.stride(1),\n",
    "            stride_V_seq=V.stride(2),\n",
    "            stride_V_dim=V.stride(3),\n",
    "            stride_O_batch=O.stride(0),\n",
    "            stride_O_head=O.stride(1),\n",
    "            stride_O_seq=O.stride(2),\n",
    "            stride_O_dim=O.stride(3),\n",
    "            BATCH_SIZE=Q.shape[0],\n",
    "            NUM_HEADS=Q.shape[1],\n",
    "            SEQ_LEN=Q.shape[2],\n",
    "            HEAD_DIM=HEAD_DIM_K,\n",
    "            STAGE=stage\n",
    "        )\n",
    "\n",
    "        # save the intermediate results for backward pass.\n",
    "        ctx.save_for_backward(Q, K, V, O, M)\n",
    "        return O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def test_op(BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM, causal, dtype=torch.float16, DEVICE='cuda'):\n",
    "    Q = (torch.empty(\n",
    "            (BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM), device=DEVICE, dtype=dtype\n",
    "        )\n",
    "        .normal_(mean=0.0, std=0.5)\n",
    "    )\n",
    "    K = (torch.empty(\n",
    "            (BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM), device=DEVICE, dtype=dtype\n",
    "        )\n",
    "        .normal_(mean=0.0, std=0.5)\n",
    "    )\n",
    "    V = (torch.empty(\n",
    "            (BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM), device=DEVICE, dtype=dtype\n",
    "        )\n",
    "        .normal_(mean=0.0, std=0.5)\n",
    "    )\n",
    "\n",
    "    softmax_scale = 1.0 / math.sqrt(HEAD_DIM)\n",
    "    # Backpropagate through the output.\n",
    "    dO = torch.randn_like(Q)\n",
    "\n",
    "    mask = torch.tril(torch.ones((SEQ_LEN, SEQ_LEN), device=DEVICE))\n",
    "    P = torch.matmul(Q, K.transpose(2, 3)) * softmax_scale\n",
    "\n",
    "    if causal:\n",
    "        P[..., mask == 0] = float('-inf')\n",
    "    P = torch.softmax(P, dim=-1).half()\n",
    "    ref_O = torch.matmul(P, V)\n",
    "\n",
    "    if False:\n",
    "        # Skip backward pass for now.\n",
    "        ref_O.backward(dO)\n",
    "\n",
    "        ref_dV, V.grad = V.grad.clone(), None\n",
    "        ref_dP, P.grad = P.grad.clone(), None\n",
    "        ref_dK, K.grad = K.grad.clone(), None\n",
    "        ref_dQ, Q.grad = Q.grad.clone(), None\n",
    "\n",
    "    # Compare with Triton implementation\n",
    "    tri_out = TritonAttention.apply(Q, K, V, causal, softmax_scale)\n",
    "    \n",
    "    # Compare\n",
    "    rtol = 0.0\n",
    "    atol = 1e-2\n",
    "    assert torch.allclose(tri_out, ref_O, rtol=rtol, atol=atol)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_op(BATCH_SIZE=4, NUM_HEADS=4, SEQ_LEN=512, HEAD_DIM=128, causal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

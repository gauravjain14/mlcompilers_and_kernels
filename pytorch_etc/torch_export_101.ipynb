{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOIymrluO/1J5gHwaTS+ntv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gauravjain14/mlcompilers_and_kernels/blob/main/pytorch_etc/torch_export_101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confused at any point, refer to https://pytorch.org/docs/stable/export.html"
      ],
      "metadata": {
        "id": "A4HmRHQIi6-5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XWW-0Nfj91Jv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.export import export"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Mod(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
        "        a = torch.sin(x)\n",
        "        b = torch.cos(y)\n",
        "        return a + b"
      ],
      "metadata": {
        "id": "xfRXykkR97ck"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Under the hood `torch.export` leverages TorchDynamo (`torch._dynamo`),\n",
        "AOT Autograd (to decompose to the ATen operator set), and Torch FX (`torch.fx`) for the underlying representation of graph for a flexible Python-based transformations."
      ],
      "metadata": {
        "id": "YtRmlcCwg-nN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_args = (torch.randn(10, 10), torch.randn(10, 10))\n",
        "\n",
        "exported_program: torch.export.ExportedProgram = export(Mod(), example_args)\n",
        "print(exported_program)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07K-89DCNoIM",
        "outputId": "8d1e210c-aa8d-42d6-fabb-e69fa9b05ff6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ExportedProgram:\n",
            "    class GraphModule(torch.nn.Module):\n",
            "        def forward(self, x: \"f32[10, 10]\", y: \"f32[10, 10]\"):\n",
            "             # File: <ipython-input-2-93a00b9c2195>:6 in forward, code: a = torch.sin(x)\n",
            "            sin: \"f32[10, 10]\" = torch.ops.aten.sin.default(x);  x = None\n",
            "            \n",
            "             # File: <ipython-input-2-93a00b9c2195>:7 in forward, code: b = torch.cos(y)\n",
            "            cos: \"f32[10, 10]\" = torch.ops.aten.cos.default(y);  y = None\n",
            "            \n",
            "             # File: <ipython-input-2-93a00b9c2195>:8 in forward, code: return a + b\n",
            "            add: \"f32[10, 10]\" = torch.ops.aten.add.Tensor(sin, cos);  sin = cos = None\n",
            "            return (add,)\n",
            "            \n",
            "Graph signature: ExportGraphSignature(input_specs=[InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='x'), target=None, persistent=None), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='y'), target=None, persistent=None)], output_specs=[OutputSpec(kind=<OutputKind.USER_OUTPUT: 1>, arg=TensorArgument(name='add'), target=None)])\n",
            "Range constraints: {}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How `torch.export()` compares with `torch.compile()`, `torch.fx.symbolic_trace`, etc. -\n",
        "\n",
        "1. When `torch.compile()` runs into an untraceable part of a model, it will \"graph break\" and fall back to running the program in eager Python runtime.\n",
        "`torch.export()` will error out when something untraceable is reached.\n",
        "\n",
        "2. `torch.export()` creates a full graph from Python features or runtime, which can be saved, loaded, and run in different environments and languages.\n",
        "\n",
        "Compared to torch.fx.symbolic_trace(), torch.export traces using TorchDynamo which operates at the Python bytecode level, giving it the ability to trace arbitrary Python constructs not limited by what Python operator overloading supports. Additionally, torch.export keeps fine-grained track of tensor metadata, so that conditionals on things like tensor shapes do not fail tracing. In general, torch.export is expected to work on more user programs, and produce lower-level graphs (at the torch.ops.aten operator level). Note that users can still use torch.fx.symbolic_trace() as a preprocessing step before torch.export."
      ],
      "metadata": {
        "id": "svz2c7Q6hfN6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nyu7UoE4N1Rt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exporting a PyTorch Model"
      ],
      "metadata": {
        "id": "ggFraBL5jNlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple module for demonstration\n",
        "class M(torch.nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.conv = torch.nn.Conv2d(\n",
        "            in_channels=3, out_channels=16, kernel_size=3, padding=1\n",
        "        )\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.maxpool = torch.nn.MaxPool2d(kernel_size=3)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, *, constant=None) -> torch.Tensor:\n",
        "        a = self.conv(x)\n",
        "        a.add_(constant)\n",
        "        return self.maxpool(self.relu(a))"
      ],
      "metadata": {
        "id": "DRJz_Kj-jOVd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_args = (torch.randn(1, 3, 224, 224),)\n",
        "example_kwargs = {\"constant\": torch.ones(1, 16, 224, 224)}\n",
        "\n",
        "exported_program: torch.export.ExportedProgram = export(M(), example_args, example_kwargs)\n",
        "print(exported_program)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZqDMhZJkYzI",
        "outputId": "8a738f5b-f330-4456-d4b7-0d30f5f651b8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ExportedProgram:\n",
            "    class GraphModule(torch.nn.Module):\n",
            "        def forward(self, p_conv_weight: \"f32[16, 3, 3, 3]\", p_conv_bias: \"f32[16]\", x: \"f32[1, 3, 224, 224]\", constant: \"f32[1, 16, 224, 224]\"):\n",
            "             # File: <ipython-input-4-99131fc297ec>:12 in forward, code: a = self.conv(x)\n",
            "            conv2d: \"f32[1, 16, 224, 224]\" = torch.ops.aten.conv2d.default(x, p_conv_weight, p_conv_bias, [1, 1], [1, 1]);  x = p_conv_weight = p_conv_bias = None\n",
            "            \n",
            "             # File: <ipython-input-4-99131fc297ec>:13 in forward, code: a.add_(constant)\n",
            "            add: \"f32[1, 16, 224, 224]\" = torch.ops.aten.add.Tensor(conv2d, constant);  conv2d = constant = None\n",
            "            \n",
            "             # File: <ipython-input-4-99131fc297ec>:14 in forward, code: return self.maxpool(self.relu(a))\n",
            "            relu: \"f32[1, 16, 224, 224]\" = torch.ops.aten.relu.default(add);  add = None\n",
            "            max_pool2d: \"f32[1, 16, 74, 74]\" = torch.ops.aten.max_pool2d.default(relu, [3, 3], [3, 3]);  relu = None\n",
            "            return (max_pool2d,)\n",
            "            \n",
            "Graph signature: ExportGraphSignature(input_specs=[InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_conv_weight'), target='conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_conv_bias'), target='conv.bias', persistent=None), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='x'), target=None, persistent=None), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='constant'), target=None, persistent=None)], output_specs=[OutputSpec(kind=<OutputKind.USER_OUTPUT: 1>, arg=TensorArgument(name='max_pool2d'), target=None)])\n",
            "Range constraints: {}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Few things learned in this -\n",
        "\n",
        "If `InputKind.PARAMETER`, Persistent=None defaults to True. What that means is that the model weights will be embedded within the graph. Thus, during deploying, separate weight files don't need to managed.\n",
        "\n",
        "The `torch.fx.Graph` contains the computation graph of the original program, along with records of the original code for easy debugging.\n",
        "\n",
        "The graph contains only `torch.ops.aten` operators.\n",
        "\n",
        "The resulting shape and dtype of tensors produced by each node in the graph is noted. For example, the convolution node will result in a tensor of dtype torch.float32 and shape (1, 16, 256, 256).\n",
        "\n",
        "\n",
        "### Next, we want to add define and add custom operator and see how it is traced."
      ],
      "metadata": {
        "id": "M4EsL6XopAlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.fx.Graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "hC3VLzPEroSI",
        "outputId": "7eaa9529-016f-4ba0-d1e5-f00ea94bb8ca"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.fx.graph.Graph"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torch.fx.graph.Graph</b><br/>def __init__(owning_module: Optional[&#x27;GraphModule&#x27;]=None, tracer_cls: Optional[Type[&#x27;Tracer&#x27;]]=None, tracer_extras: Optional[Dict[str, Any]]=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/torch/fx/graph.py</a>``Graph`` is the main data structure used in the FX Intermediate Representation.\n",
              "It consists of a series of ``Node`` s, each representing callsites (or other\n",
              "syntactic constructs). The list of ``Node`` s, taken together, constitute a\n",
              "valid Python function.\n",
              "\n",
              "For example, the following code\n",
              "\n",
              ".. code-block:: python\n",
              "\n",
              "    import torch\n",
              "    import torch.fx\n",
              "\n",
              "    class MyModule(torch.nn.Module):\n",
              "        def __init__(self):\n",
              "            super().__init__()\n",
              "            self.param = torch.nn.Parameter(torch.rand(3, 4))\n",
              "            self.linear = torch.nn.Linear(4, 5)\n",
              "\n",
              "        def forward(self, x):\n",
              "            return torch.topk(torch.sum(self.linear(x + self.linear.weight).relu(), dim=-1), 3)\n",
              "\n",
              "    m = MyModule()\n",
              "    gm = torch.fx.symbolic_trace(m)\n",
              "\n",
              "Will produce the following Graph::\n",
              "\n",
              "    print(gm.graph)\n",
              "\n",
              ".. code-block:: text\n",
              "\n",
              "    graph(x):\n",
              "        %linear_weight : [num_users=1] = self.linear.weight\n",
              "        %add_1 : [num_users=1] = call_function[target=operator.add](args = (%x, %linear_weight), kwargs = {})\n",
              "        %linear_1 : [num_users=1] = call_module[target=linear](args = (%add_1,), kwargs = {})\n",
              "        %relu_1 : [num_users=1] = call_method[target=relu](args = (%linear_1,), kwargs = {})\n",
              "        %sum_1 : [num_users=1] = call_function[target=torch.sum](args = (%relu_1,), kwargs = {dim: -1})\n",
              "        %topk_1 : [num_users=1] = call_function[target=torch.topk](args = (%sum_1, 3), kwargs = {})\n",
              "        return topk_1\n",
              "\n",
              "For the semantics of operations represented in the ``Graph``, please see :class:`Node`.\n",
              "\n",
              ".. note::\n",
              "    Backwards-compatibility for this API is guaranteed.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 827);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BDlFi7AisQqm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling and Expressing Dynamism\n",
        "\n",
        "By default, `torch.export` will trace the program assuming all shapes are static, and specialize the exported program to those dimensions.\n",
        "\n",
        "However, some dimensions like the Batch Dimension can be dynamic and vary from run to run.\n",
        "\n",
        "Such dimensions are specified using the `torch.export.Dim()` API and by passing the same to `torch.export.export()` using `dynamic_shapes` argument."
      ],
      "metadata": {
        "id": "Aab_dkhS_GlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.export import Dim\n",
        "\n",
        "class M(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.branch1 = torch.nn.Sequential(\n",
        "            torch.nn.Linear(64, 32), torch.nn.ReLU()\n",
        "        )\n",
        "        self.branch2 = torch.nn.Sequential(\n",
        "            torch.nn.Linear(128, 64), torch.nn.ReLU()\n",
        "        )\n",
        "        self.buffer = torch.ones(32)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        out1 = self.branch1(x1)\n",
        "        out2 = self.branch2(x2)\n",
        "        return (out1 + self.buffer, out2)"
      ],
      "metadata": {
        "id": "jXZK0V-z_eUD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_args = (torch.randn(32, 64), torch.randn(32, 128))\n",
        "\n",
        "# Create a dynamic batch size\n",
        "batch = Dim(\"batch\")\n",
        "# Specify that the first dimension of each input is that batch size\n",
        "dynamic_shapes = {\"x1\": {0: batch}, \"x2\": {0: batch}}\n",
        "\n",
        "exported_program = export(M(), example_args, dynamic_shapes=dynamic_shapes)\n",
        "print(exported_program)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKQksZm8_ihW",
        "outputId": "303144a3-7638-4645-c0d9-d9ef4980a6b6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ExportedProgram:\n",
            "    class GraphModule(torch.nn.Module):\n",
            "        def forward(self, p_branch1_0_weight: \"f32[32, 64]\", p_branch1_0_bias: \"f32[32]\", p_branch2_0_weight: \"f32[64, 128]\", p_branch2_0_bias: \"f32[64]\", c_buffer: \"f32[32]\", x1: \"f32[s0, 64]\", x2: \"f32[s0, 128]\"):\n",
            "             # File: <ipython-input-10-34a0f04649d0>:16 in forward, code: out1 = self.branch1(x1)\n",
            "            linear: \"f32[s0, 32]\" = torch.ops.aten.linear.default(x1, p_branch1_0_weight, p_branch1_0_bias);  x1 = p_branch1_0_weight = p_branch1_0_bias = None\n",
            "            relu: \"f32[s0, 32]\" = torch.ops.aten.relu.default(linear);  linear = None\n",
            "            \n",
            "             # File: <ipython-input-10-34a0f04649d0>:17 in forward, code: out2 = self.branch2(x2)\n",
            "            linear_1: \"f32[s0, 64]\" = torch.ops.aten.linear.default(x2, p_branch2_0_weight, p_branch2_0_bias);  x2 = p_branch2_0_weight = p_branch2_0_bias = None\n",
            "            relu_1: \"f32[s0, 64]\" = torch.ops.aten.relu.default(linear_1);  linear_1 = None\n",
            "            \n",
            "             # File: <ipython-input-10-34a0f04649d0>:18 in forward, code: return (out1 + self.buffer, out2)\n",
            "            add_12: \"f32[s0, 32]\" = torch.ops.aten.add.Tensor(relu, c_buffer);  relu = c_buffer = None\n",
            "            return (add_12, relu_1)\n",
            "            \n",
            "Graph signature: ExportGraphSignature(input_specs=[InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_branch1_0_weight'), target='branch1.0.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_branch1_0_bias'), target='branch1.0.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_branch2_0_weight'), target='branch2.0.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_branch2_0_bias'), target='branch2.0.bias', persistent=None), InputSpec(kind=<InputKind.CONSTANT_TENSOR: 4>, arg=TensorArgument(name='c_buffer'), target='buffer', persistent=True), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='x1'), target=None, persistent=None), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='x2'), target=None, persistent=None)], output_specs=[OutputSpec(kind=<OutputKind.USER_OUTPUT: 1>, arg=TensorArgument(name='add_12'), target=None), OutputSpec(kind=<OutputKind.USER_OUTPUT: 1>, arg=TensorArgument(name='relu_1'), target=None)])\n",
            "Range constraints: {s0: VR[0, int_oo]}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the inputs x1 and x2, they have a symbolic shape of (s0, 64) and (s0, 128)\n",
        "\n",
        "Also look at the `exported_program.range_constraints` to see the ranges of each symbol appearing in the graph.\n",
        "\n",
        "**Need to understand range_constraints more, in depth**\n",
        "\n",
        "https://docs.google.com/document/d/16VPOa3d-Liikf48teAOmxLc92rgvJdfosIy-yoT38Io/edit?fbclid=IwAR3HNwmmexcitV0pbZm_x1a4ykdXZ9th_eJWK-3hBtVgKnrkmemz6Pm5jRQ#heading=h.ez923tomjvyk\n"
      ],
      "metadata": {
        "id": "nyfol_udBdLU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jdHyLmTg_sn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Specializations\n",
        "A key concept in understanding the behavior of torch.export is the difference between static and dynamic values.\n",
        "\n",
        "A dynamic value is one that can change from run to run. These behave like normal arguments to a Python function—you can pass different values for an argument and expect your function to do the right thing. Tensor data is treated as dynamic.\n",
        "\n",
        "A static value is a value that is fixed at export time and cannot change between executions of the exported program. When the value is encountered during tracing, the exporter will treat it as a constant and hard-code it into the graph.\n",
        "\n",
        "When an operation is performed (e.g. x + y) and all inputs are static, then the output of the operation will be directly hard-coded into the graph, and the operation won’t show up (i.e. it will get constant-folded).\n",
        "\n",
        "When a value has been hard-coded into the graph, we say that the graph has been specialized to that value.\n"
      ],
      "metadata": {
        "id": "QOxIo3p8CZYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implications of Specializations is that when shape-dependent control flow is\n",
        "# encountered. `torch.export` will specialize on the branh that is being taken\n",
        "# with the given sample inputs"
      ],
      "metadata": {
        "id": "GB3FLa1FCdOo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.export import export\n",
        "\n",
        "class Mod(torch.nn.Module):\n",
        "    def forward(self, x):\n",
        "        if x.shape[0] > 5:\n",
        "            return x + 1\n",
        "        else:\n",
        "            return x - 1\n",
        "\n",
        "# The shape is assumed to be static here since Dim() is not used to hint\n",
        "example_inputs = (torch.rand(10, 2),)\n",
        "exported_program = export(Mod(), example_inputs)\n",
        "print(exported_program)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2toibQjOCr5r",
        "outputId": "39a8ba41-2297-4344-9b54-f470cf85a8e7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ExportedProgram:\n",
            "    class GraphModule(torch.nn.Module):\n",
            "        def forward(self, x: \"f32[10, 2]\"):\n",
            "             # File: <ipython-input-13-952f5532b81e>:7 in forward, code: return x + 1\n",
            "            add: \"f32[10, 2]\" = torch.ops.aten.add.Tensor(x, 1);  x = None\n",
            "            return (add,)\n",
            "            \n",
            "Graph signature: ExportGraphSignature(input_specs=[InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='x'), target=None, persistent=None)], output_specs=[OutputSpec(kind=<OutputKind.USER_OUTPUT: 1>, arg=TensorArgument(name='add'), target=None)])\n",
            "Range constraints: {}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As visible, the static shape `(10, 2)` is not visible in the graph since `torch.export` specializes on the inputs' static shapes.\n",
        "\n",
        "To capture the same, dimension 0 need to be marked as Dim()"
      ],
      "metadata": {
        "id": "5NXd_V8aC0As"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PKm39e6IC0b5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next - `torch.export` for Training and Inference\n",
        "\n",
        "This section is a ToDo because these are features are introduced in PyTorch 2.5 and beyond.\n",
        "\n"
      ],
      "metadata": {
        "id": "6P5tp9TP9mZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# decomp_table = torch.export.default_decompositions()"
      ],
      "metadata": {
        "id": "1MgsKRK39rPN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "d1s2F8FE-nZJ",
        "outputId": "f3167196-9838-42be-bd06-32a5149be23d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.5.1+cu124'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QcP0C-A--qMB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}